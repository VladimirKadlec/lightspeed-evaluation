# LightSpeed Evaluation Framework - Sample/Mock Data

- conversation_group_id: conv_group_1
  description: conversation group description
  tag: basic  # Tag for grouping eval conversations (default: "eval")

  conversation_metrics: []
  conversation_metrics_metadata: {}
  turns:
    - turn_id: turn_id1
      query: What is the capital of France?
      expected_response: Paris
      expected_tool_calls: null
      turn_metrics:
      - ragas:response_relevancy
      turn_metrics_metadata:
        ragas:response_relevancy:
          threshold: 0.9
      verify_script: null
  setup_script: null
  cleanup_script: null
